{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import evaluate\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict\n",
    "import os\n",
    "from utils import prepare_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = 5000\n",
    "\n",
    "dataset_mlsum = load_dataset(\"mlsum\", \"fr\", cache_dir=\"/Data/gabriel-mercier/hf_datasets\")\n",
    "#dataset_wiki = load_dataset(\"wikipedia\", \"20220301.fr\", cache_dir=\"/Data/gabriel-mercier/hf_datasets\")\n",
    "\n",
    "dataset_init = dataset_mlsum['train'].shuffle(seed=42).select(range(5000)) \n",
    "dataset = dataset_init.select_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 5000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "tokenizer_llm = AutoTokenizer.from_pretrained(llm_name, \n",
    "                                          cache_dir=\"/Data/gabriel-mercier/hf_models\",\n",
    "                                          padding_side='left') #auto reggressive llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006d647859974c4fae18f50b4383df18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distibution')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_token_length(example):\n",
    "    tokens = tokenizer_llm(example[\"text\"], truncation=True, max_length=6000)[\"input_ids\"]\n",
    "    return {\"token_length\": len(tokens)}\n",
    "\n",
    "dataset_token = dataset.map(get_token_length)\n",
    "\n",
    "plt.hist(dataset_token[\"token_length\"], bins=100)\n",
    "plt.xlabel(\"Number of tokens\")\n",
    "plt.ylabel(\"Total\")\n",
    "plt.title(\"Distibution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2500\u001b[39m\n",
      "\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "max_length = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  3 00:52:47 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.04             Driver Version: 570.124.04     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A5000               Off |   00000000:01:00.0 Off |                  Off |\n",
      "| 59%   83C    P2            229W /  230W |   20709MiB /  24564MiB |     95%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A          285009      G   /usr/libexec/Xorg                        94MiB |\n",
      "|    0   N/A  N/A          285160      G   /usr/bin/gnome-shell                     19MiB |\n",
      "|    0   N/A  N/A         1118742      C   ...rcier/INF_CV/myenv/bin/python      20552MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b474522810948c688723b104b35746d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  \n",
    "    bnb_4bit_compute_dtype=torch.float16, \n",
    "    bnb_4bit_use_double_quant=True,  \n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "model_llm = AutoModelForCausalLM.from_pretrained(\n",
    "    llm_name,\n",
    "    cache_dir=\"/Data/gabriel-mercier/hf_models\",\n",
    "    quantization_config=bnb_config, \n",
    "    device_map=\"auto\"  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "assistant_start = \"Voici le résumé de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_num_tokens = 250\n",
    "\n",
    "def generate_summary(text):\n",
    "    prompt = prepare_prompt({'text':text}, summary_included=False)\n",
    "    inputs = tokenizer_llm(prompt, return_tensors=\"pt\", truncation=True, max_length=max_length).to(model_llm.device)\n",
    "    prompt_length = inputs.input_ids.shape[-1] \n",
    "    output = model_llm.generate(**inputs, max_new_tokens=summary_num_tokens)\n",
    "    generated_tokens = output[0][prompt_length:]\n",
    "    summary = tokenizer_llm.decode(generated_tokens, skip_special_tokens=True)\n",
    "    summary = summary.split(\"\\n\")\n",
    "    summary = next((s for s in summary if s.strip()), None)\n",
    "    summary_split = summary.split()\n",
    "    summary = \" \".join(summary_split[:125])\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Willem-Alexander, incognito. Jason Reed / REUTERS Willem-Alexander, devenu roi des Pays-Bas en 2013, exerçait un autre métier à temps partiel depuis vingt et un ans : pilote de ligne pour la compagnie néerlandaise KLM. Le monarque a révélé sa double vie au journal De Telegraaf, le 18 mai. Il raconte qu’il volait au moins deux fois par mois sur des Fokker 70 couvrant des courtes distances en Europe du Nord. Il officiait en tant que copilote mais ne révélait jamais sa vraie identité à ses passagers. « L’avantage, c’est que je pouvais toujours les accueillir au nom du capitaine et de l’équipage. Je n’étais pas obligé de dire mon nom. » Il se souvient qu’avant le 11-Septembre, quand l’accès au cockpit était encore autorisé aux plus curieux, « des gens venaient régulièrement jeter un coup d’œil et étaient surpris et contents de m’y voir assis ». Mais tout compte fait, sur deux décennies, peu de gens ont reconnu sa voix – « de toute façon, la plupart des gens n’écoutent pas » – ou son visage, derrière la casquette de pilote et les lunettes. La vie rêvée des pilotes La passion du roi pour le pilotage était connue et médiatisée par la couronne et le gouvernement, qui avaient même révélé en avril que Willem-Alexander avait effectué quelques vols commerciaux pour que sa licence n’expire pas. C’est par l’interview de leur roi que les 17 millions de Néerlandais ont appris que c’était bien plus qu’un simple hobby. Avant son accession au trône, Willem-Alexander avait confié à ses proches que s’il n’était pas né dans un palais et dans les obligations qui en découlaient, son rêve aurait été de piloter les plus gros avions commerciaux. Copiloter incognito était la façon de s’en approcher le plus. Il décrit cette passion ainsi à De Telegraaf : « Vous avez un avion, des passagers et un équipage, et ils sont sous votre responsabilité. Vous ne pouvez pas amener vos problèmes avec vous dans les airs. Vous pouvez complètement débrancher pendant un moment et vous concentrer sur autre chose. » Si le roi néerlandais parle aujourd’hui de sa vie cachée, c’est que la flotte de Fokkers de KLM va être décommissionnée. Pour continuer à vivre (un peu) son rêve, il va devoir s’entraîner au pilotage du Boeing 737 pour, comme il dit, peut-être un jour « voler vers d’autres destinations, plus lointaines, avec plus de passagers ». Le roi n’a pas dit s’il allait continuer à faire des petites distances ou enchaîner directement avec les plus longues. Mais il le fera incognito.\n",
      "Summary : Willem-Alexander, roi des Pays-Bas depuis 2013, a révélé avoir été pilote commercial pour KLM pendant 21 ans. Il volait incognito en tant que copilote sur des Fokker 70, accueillant les passagers sans révéler son identité. Sa passion pour le pilotage était connue, mais peu savaient qu'il volait régulièrement. Il aimait se concentrer sur sa tâche et \"débrancher\" des soucis royaux. Avec la fin des Fokkers, il envisage de s'entraîner au Boeing 737 pour voler plus loin, toujours incognito. Cette révélation a surpris les Néerlandais, découvrant que leur roi avait une vie cachée si différente de ses obligations royales. Le roi explique que piloter lui permettait de s'évader et de se concentrer sur autre chose. Il a pu vivre un peu son rêve de piloter les\n",
      "125\n",
      "Cours au collège Gabriel-Guist’Hau de Nantes, en 2012. FRANK PERRY / AFP A un an de l’élection présidentielle, la gauche s’apprête à décider d’un vaste plan de revalorisation salariale en direction d’un électorat qui lui est traditionnellement acquis : les enseignants. Le ministère de l’éducation nationale ouvre, mercredi 1er juin, des négociations avec les organisations syndicales sur de nouvelles mesures de revalorisation et de déroulement de carrière qui toucheront progressivement, dans les trois prochaines années, l’ensemble des enseignants et personnels d’éducation. Cette déclinaison pour les enseignants du protocole « parcours professionnels, carrières et rémunérations » (PPCR) dans la fonction publique, validé à l’automne 2015, entraîne pour le seul ministère de l’éducation un budget prévu d’un milliard d’euros de hausses de salaires d’ici à 2020, dont la moitié en 2017. L’opposition ne manquera pas d’y voir autant de cadeaux distribués dans le cadre d’une opération de reconquête électorale C’est donc une nouvelle page qui s’ouvre au chapitre de la revalorisation des enseignants, après l’annonce, début mai, de l’alignement de la prime des professeurs des écoles sur celle du secondaire (1 200 euros par an) et celle, en mars, du dégel du point d’indice des fonctionnaires. L’opposition ne manquera pas d’y voir autant de cadeaux distribués dans le cadre d’une opération de reconquête électorale. Toujours est-il que ces nouvelles mesures arrivent à point nommé, dans un contexte de contestations de la réforme du collège. D’une manière générale, les enseignants, bousculés depuis le début du quinquennat par une longue série de réformes, n’ont pas toujours compris le sens des orientations prises, ni perçu les effets concrets des 47 000 postes créés (sur les 60 000 promis d’ici à 2017). Article réservé à nos abonnés Lire aussi « Collège 2016 » : le gouvernement prend le risque de rendre illisible la « refondation » de l’école « Rattraper le retard de la France » Les effets de cette revalorisation devraient, en revanche, être bel et bien visibles sur la fiche de paie. « Ces nouvelles mesures vont permettre de replacer la France au-dessus de la moyenne de l’OCDE, et d’atteindre, en fin de carrière, le niveau des pays les plus favorables, se félicite la ministre de l’éducation nationale, Najat Vallaud-Belkacem. Sur ce sujet, la France était à la traîne ; nous allons rattraper ce retard. » Dans la grille de rémunération des professeurs, tous les échelons vont monter d’un cran (de 9 à 40 points) d’ici à 2020. Un enseignant certifié gagnera 23 000 euros de plus sur l’ensemble de sa carrière. L’effort est particulièrement soutenu à l’entrée dans le métier : les stagiaires percevront 1 400 euros bruts par an de plus qu’actuellement. « Ce troisième grade, c’est un peu l’agrégation pour tous : elle donne la possibilité d’atteindre un niveau de rémunération proche de celui d’un agrégé en fin de carrière, soit 4 500 euros bruts par mois » Frédéric Sève, SGEN-CFDT A ces gains s’ajoute une amélioration de la carrière. Aujourd’hui, celle-ci est divisée en deux « grades » : une « classe normale », dans laquelle les enseignants sont recrutés, et une « hors-classe », dans laquelle ils peuvent être promus selon des critères plus ou moins flous. A compter de 2017, tous accéderont au grade hors-classe. De plus, un nouvel étage supérieur sera créé : une « classe exceptionnelle », accessible en priorité à ceux ayant exercé en éducation prioritaire, ou ayant occupé des responsabilités (directeur d’école, formateur, conseiller pédagogique…) pendant au moins huit ans. « Ce troisième grade, c’est un peu l’agrégation pour tous : elle donne la possibilité d’atteindre un niveau de rémunération proche de celui d’un agrégé en fin de carrière, soit 4 500 euros bruts par mois », salue Frédéric Sève, du SGEN-CFDT. Autant de mesures consensuelles, qui ne devraient guère être révisées lors des négociations. « La dernière revalorisation des enseignants remonte à plus d’un quart de siècle, sous Lionel Jospin [alors ministre de l’éducation] qui, en 1989, avait créé la hors-classe. Il y avait nécessité absolue », souligne Christian Chevalier, du SE-UNSA. Sous la présidence de Nicolas Sarkozy, une revalorisation avait été annoncée en échange de suppressions de postes. Mais hormis la défiscalisation des heures supplémentaires et un geste pour les débuts de carrière, elle n’a jamais eu lieu. Premier syndicat du secondaire, le SNES-FSU reconnaît « un premier pas que nous actons positivement. Même si dans un contexte de crise de recrutement, il en faudrait davantage pour rendre nos professions plus attractives », estime Xavier Marand, secrétaire général adjoint. L’autre volet de la négociation, qui concerne l’évaluation des professeurs, risque de créer plus de clivages. Aujourd’hui, les enseignants sont inspectés en moyenne tous les cinq ans. En fonction de la note qui en découle, couplée avec celle du chef d’établissement, ils changent d’échelon selon trois rythmes : « ancienneté », « choix » et « grand choix ». Conséquence du PPCR, l’évolution dans la carrière se fera désormais au même rythme pour tous. Les trois rythmes d’avancement disparaissent donc, tout comme la double notation. Mais le ministère ne remet pas pour autant en cause le principe d’une évolution de carrière au mérite : « Nous proposons quatre rendez-vous de carrière pour apprécier la valeur professionnelle des enseignants : après sept ans, treize ans, vingt ans et en fin de carrière. A chacun de ces rendez-vous, un enseignant pourra se voir proposer une accélération de carrière et de nouvelles perspectives. » Article réservé à nos abonnés Lire aussi Du latin aux classes bilangues, un an de polémiques sur la réforme du collège Qui évaluera les enseignants ? En dehors de ces quatre moments, « les finalités de l’évaluation des enseignants seront réorientées vers l’accompagnement, la formation continue, le conseil individuel et collectif », précise le ministère. Reste à savoir qui évaluera les enseignants lors de ces rendez-vous, comment et sur quels critères. « Dans ce schéma, l’inspection continuera à être ballottée entre deux objectifs : le jugement, avec un impact sur la carrière, et l’accompagnement. On reste au milieu du gué », déplore Sébastien Sihr, du SNUipp-FSU, principal syndicat dans le primaire. Un groupe de travail doit plancher sur le sujet pour une remise de copie avant la fin du mois de juillet. La dernière réforme de l’évaluation des enseignants, conçue par la droite – qui faisait endosser au chef d’établissement le rôle d’évaluateur en lieu et place de l’inspecteur –, avait été très contestée. Publiée au lendemain de la présidentielle de 2012, elle avait été aussitôt recalée par la gauche, dès l’entrée en fonction de François Hollande. Article réservé à nos abonnés Lire aussi Réforme du collège : un an de préparation, et toujours beaucoup d’inquiétudes\n",
      "Summary : La gauche prépare un plan de revalorisation salariale des enseignants, coûtant 1 milliard d'euros d'ici 2020. Les salaires augmenteront progressivement, avec des gains importants à l'entrée dans le métier. Un nouveau \"grade\" sera créé. L'évaluation des enseignants évoluera vers quatre rendez-vous de carrière. Ces mesures interviennent dans un contexte de contestations de réformes éducatives. L'opposition les voit comme des cadeaux électoraux. Les syndicats saluent globalement l'initiative mais restent vigilants sur les modalités d'évaluation.\n",
      "73\n",
      "Le correspondant de RFI en langue haoussa au Cameroun, Ahmed Abba, est sorti de prison vendredi 22 décembre, après vingt-neuf mois de détention, a-t-on appris auprès de son avocat. « Ahmed Abba a quitté la prison de Yaoundé vers 21 h 15. Il est avec moi depuis sa sortie, il se porte bien », a déclaré Me Charles Tchoungang. L’information a été confirmée par la rédaction de RFI. Condamné en 2016 à dix ans de prison pour « blanchiment d’actes de terrorisme », M. Abba a été acquitté jeudi de cette accusation par le tribunal militaire de Yaoundé, mais condamné à vingt-quatre mois de prison pour « non-dénonciation ». Il était donc, de fait, libérable, après avoir passé vingt-neuf mois en préventive. Jeudi soir, la direction de RFI s’était dite « soulagée à la perspective de cette libération imminente permise par la justice camerounaise ». Soulignant la « vacuité du dossier d’accusation », RFI avait réaffirmé « qu’en dépit de cette condamnation déjà soldée par les années passées en détention, Ahmed Abba n’a fait que son travail de journaliste ». Boko Haram Correspondant de RFI dans le nord du Cameroun, le journaliste avait été arrêté en juillet 2015 à Maroua (nord), où il couvrait la crise liée au groupe djihadiste nigérian Boko Haram. Il était soupçonné par les autorités d’avoir collaboré avec les terroristes et de ne pas avoir partagé les informations qu’il détenait. Son procès en appel a connu de multiples reports ces derniers mois. Son procès en première instance avait été reporté à 18 reprises pendant deux ans.\n",
      "Summary : Le journaliste camerounais Ahmed Abba, correspondant de RFI en haoussa, a été libéré vendredi 22 décembre après 29 mois de détention. Condamné en 2016 à 10 ans pour \"blanchiment d'actes de terrorisme\", il a été acquitté de ce chef d'accusation mais condamné à 24 mois pour \"non-dénonciation\". Arrêté en 2015 à Maroua, il était accusé de collusion avec Boko Haram et de non-partage d'informations. Son procès a connu de nombreux reports. Sa libération a été saluée par RFI qui souligne l'absence de preuves contre lui. Le journaliste est désormais libre après avoir purgé sa peine.\n",
      "95\n",
      "La candidate à l’investiture démocrate Hillary Clinton à Long Beach, en Californie, lundi 6 juin 2016. MIKE BLAKE / REUTERS Le fait du jour L’agence de presse américaine Associated Press (AP) a pris de court les deux candidats à l’investiture démocrate, Hillary Clinton et Bernie Sanders, en annonçant lundi 6 juin au soir que la première disposait désormais du nombre de délégués nécessaires pour être adoubée par son parti. L’agence a établi sa réputation dans le décompte parfois byzantin des votes exprimés lors de la convention à venir, en juillet, en tenant à jour les choix des super-délégués, ces cadres du parti qui constituent un corps électoral spécifique et qui ne sont pas désignés lors des caucus et primaires. Lundi matin, il ne manquait à Mme Clinton que 26 voix. En ajoutant les 1 812 délégués élus aux 571 super-délégués, elle parvient au seuil nécessaire de 2 383 voix. A la veille des primaires organisées dans six Etats, l’ancienne secrétaire d’Etat s’est dite « flattée », tout en annonçant qu’elle ferait campagne jusqu’au bout. L’équipe de campagne de M. Sanders a jugé pour sa part « malencontreuse » et « précipitée » l’information de AP. Le sénateur indépendant du Vermont estime que les voix des super-délégués ne peuvent pas être prises en compte avant la convention et que Mme Clinton est donc encore loin du compte. We’re flattered, @AP, but we've got primaries to win. CA, MT, NM, ND, NJ, SD, vote tomorrow! https://t.co/8t3GpZqc1U — HillaryClinton (@Hillary Clinton) La citation du jour « Est-ce que vous avez reçu d’autres lettres stupides ? » Selon l’agence Bloomberg, le futur candidat républicain à la présidentielle, Donald Trump, a incité ses partisans à continuer d’attaquer le juge de Californie qui instruit des plaintes visant des formations au management controversées dispensées sous le nom de Trump University. M. Trump met en cause les origines mexicaines du juge, ce qui a provoqué le malaise de nombreux responsables républicains. Au cours de la conférence téléphonique organisée lundi 6 juin, M. Trump a vivement critiqué une directive émanant de son quartier général qui invitait les soutiens du milliardaire à éviter le sujet. La vidéo du jour Interrogé par téléphone dans le cadre de l’émission Fox and Friends, lundi 6 juin au matin, le futur candidat républicain s’est flatté de priver d’accès à sa campagne des journalistes, citant l’exemple d’une reporter de la chaîne NBC. Le chiffre du jour 2 points Selon la compilation de sondages réalisée par le site RealClearPolitics, Hillary Clinton l’emporterait de justesse en Californie, mardi 7 juin, avec 2 points d’avance sur son adversaire démocrate, Bernie Sanders. L’ex-secrétaire d’Etat est créditée de 49 % des voix contre 47 % pour son rival. Toutefois, les instituts de sondages restent prudents. L’écart se situe dans la marge d’erreur, et les dernières semaines ont clairement montré une remontée du sénateur du Vermont. La photo du jour Le chien Frisco déguisé en Bernie Sanders, candidat à l’investiture démocrate, à San Francisco, lundi 6 juin. Noah Berger / AP A suivre Le dernier grand rendez-vous des primaires démocrates se tient mardi 7 juin avec les votes dans le New Jersey, la Californie, le Dakota du Nord, le Dakota du Sud, le Montana et le Nouveau-Mexique. Donnée d’ores et déjà gagnante par l’agence AP, lundi, Hillary Clinton paraît assurée de l’emporter dans l’un des deux grands Etats en jeu, le New Jersey, mais son adversaire Bernie Sanders espère en faire de même en Californie, le plus peuplé des Etats-Unis.\n",
      "Summary : Lundi 6 juin, l'Associated Press a annoncé que Hillary Clinton avait obtenu suffisamment de délégués pour être investie par le parti démocrate. Ce décompte inclut les super-délégués, critiqués par Bernie Sanders. Clinton a affirmé qu'elle continuerait sa campagne. Dans une autre actualité, Donald Trump a encouragé ses partisans à attaquer le juge mexicain instruisant des affaires liées à Trump University. Les primaires clés auront lieu mardi en Californie et autres États. Clinton est légèrement favorite en Californie selon les sondages. Les candidats démocrates se disputent l'investiture lors des derniers votes de la primaire.\n",
      "93\n",
      "Au Mawjoudin Queer Film Festival, en janvier 2018, à Tunis. Mawjoudin We Exist/Facebook Douze films sont au programme du Mawjoudin Queer Film Festival, le premier festival cinématographique queer en Tunisie, du lundi 15 au jeudi 18 janvier, à Tunis. Organisé par Mawjoudin, une association tunisienne qui défend les droits des personnes lesbiennes, gays, bisexuelles et transgenres (LGBT), ce festival veut, à travers l’art, faire une place aux minorités sexuelles et défendre leurs droits, dans une société où l’homosexualité reste illégale et réprouvée. Cet événement prévoit la diffusion de courts-métrages de quinze à vingt minutes, réalisés en Tunisie et dans tout le Moyen-Orient et l’Afrique du Nord. Ils parlent « de sexualité, d’identité et de l’expression du genre », affirme à l’AFP Senda Ben Jebara, membre de l’organisation. Le message est que « nous sommes différents mais que la différence est la bienvenue ici », ajoute-t-elle. « A travers ce festival, nous voulons donner un espace aux gens queer en général pour échapper à la pression sociale et pouvoir s’identifier à quelque chose, trouver un moyen de s’exprimer, poursuit Mme Ben Jebara. Nous nous battons non seulement au niveau légal mais aussi à travers l’art. » Pour Mourad, un étudiant de 21 ans venu assister à une projection, cet espace « permet de rassembler les personnes jugées différentes et de renforcer la communauté LGBT ». Une webradio Depuis la révolution de 2011, les militants LGBT sont sortis de l’ombre en Tunisie, mais leur condition reste très précaire du fait d’un rejet social encore violent et d’une législation hostile. L’article 230 du Code pénal condamne ainsi l’homosexualité d’une peine allant jusqu’à trois ans de prison. En décembre 2017, une webradio destinée à la communauté LGBT, la première du genre dans le monde arabe, a vu le jour en Tunisie pour défendre les droits des minorités sexuelles. Lancée par l’association Shams, l’un des porte-drapeau de la communauté LGBT dans le pays, Shams Rad vise, selon son directeur Bouhdid Belhadi, « à sensibiliser citoyens ordinaires et décideurs politiques à l’homophobie de la société et à défendre les libertés individuelles ». Mais la radio a été assignée en justice et une procédure est en cours visant à sa fermeture. Aucune abrogation de l’article 230 n’est à l’ordre du jour. Elle « n’aura pas lieu », avait assuré en 2015 le président tunisien, Béji Caïd Essebsi, lors d’un entretien avec une chaîne de télévision égyptienne.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "\u001b[0;32m----> 5\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary :\u001b[39m\u001b[38;5;124m\"\u001b[39m, summary)\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(summary\u001b[38;5;241m.\u001b[39msplit()))\n",
      "\n",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m, in \u001b[0;36mgenerate_summary\u001b[0;34m(text)\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer_llm(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39mmax_length)\u001b[38;5;241m.\u001b[39mto(model_llm\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;32m      6\u001b[0m prompt_length \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \n",
      "\u001b[0;32m----> 7\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary_num_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      8\u001b[0m generated_tokens \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m][prompt_length:]\n",
      "\u001b[1;32m      9\u001b[0m summary \u001b[38;5;241m=\u001b[39m tokenizer_llm\u001b[38;5;241m.\u001b[39mdecode(generated_tokens, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n",
      "\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n",
      "\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/transformers/generation/utils.py:2223\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   2215\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n",
      "\u001b[1;32m   2216\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n",
      "\u001b[1;32m   2217\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n",
      "\u001b[1;32m   2218\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n",
      "\u001b[1;32m   2219\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n",
      "\u001b[1;32m   2220\u001b[0m     )\n",
      "\u001b[1;32m   2222\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n",
      "\u001b[0;32m-> 2223\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   2224\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   2225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   2226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   2227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   2228\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   2229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   2230\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   2233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n",
      "\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n",
      "\u001b[1;32m   2235\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n",
      "\u001b[1;32m   2236\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n",
      "\u001b[1;32m   2237\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   2242\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n",
      "\u001b[1;32m   2243\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/transformers/generation/utils.py:3214\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n",
      "\u001b[1;32m   3212\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;32m   3213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 3214\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   3216\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n",
      "\u001b[1;32m   3217\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n",
      "\u001b[1;32m   3218\u001b[0m     outputs,\n",
      "\u001b[1;32m   3219\u001b[0m     model_kwargs,\n",
      "\u001b[1;32m   3220\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n",
      "\u001b[1;32m   3221\u001b[0m )\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n",
      "\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n",
      "\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py:856\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    853\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n",
      "\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n",
      "\u001b[0;32m--> 856\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    870\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py:579\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n",
      "\u001b[1;32m    567\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n",
      "\u001b[1;32m    568\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n",
      "\u001b[1;32m    569\u001b[0m         hidden_states,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    576\u001b[0m         position_embeddings,\n",
      "\u001b[1;32m    577\u001b[0m     )\n",
      "\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 579\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    591\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py:260\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    257\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n",
      "\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n",
      "\u001b[0;32m--> 260\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    270\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    271\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py:162\u001b[0m, in \u001b[0;36mQwen2Attention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    159\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;32m    160\u001b[0m hidden_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n",
      "\u001b[0;32m--> 162\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;32m    163\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;32m    164\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/bitsandbytes/nn/modules.py:484\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x)\u001b[0m\n",
      "\u001b[1;32m    480\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n",
      "\u001b[1;32m    482\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n",
      "\u001b[0;32m--> 484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(inp_dtype)\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/bitsandbytes/autograd/_functions.py:528\u001b[0m, in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n",
      "\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MatMul4Bit\u001b[38;5;241m.\u001b[39mapply(A, B, out, bias, quant_state)\n",
      "\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 528\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemv_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    530\u001b[0m         out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bias\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/bitsandbytes/functional.py:1974\u001b[0m, in \u001b[0;36mgemv_4bit\u001b[0;34m(A, B, out, transposed_A, transposed_B, state)\u001b[0m\n",
      "\u001b[1;32m   1972\u001b[0m absmax \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mabsmax\n",
      "\u001b[1;32m   1973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mnested:\n",
      "\u001b[0;32m-> 1974\u001b[0m     absmax \u001b[38;5;241m=\u001b[39m \u001b[43mdequantize_blockwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabsmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1975\u001b[0m     absmax \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39moffset\n",
      "\u001b[1;32m   1977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/bitsandbytes/functional.py:1025\u001b[0m, in \u001b[0;36mdequantize_blockwise\u001b[0;34m(A, quant_state, absmax, code, out, blocksize, nested)\u001b[0m\n",
      "\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m quant_state\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m4096\u001b[39m, \u001b[38;5;241m2048\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m]:\n",
      "\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[1;32m   1022\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe blocksize of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquant_state\u001b[38;5;241m.\u001b[39mblocksize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported. Supported values: [4096, 2048, 1024, 512, 256, 128, 64]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m   1023\u001b[0m     )\n",
      "\u001b[0;32m-> 1025\u001b[0m \u001b[43mis_on_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabsmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _cuda_device_of(A):\n",
      "\u001b[1;32m   1028\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[1;32m   1029\u001b[0m         get_ptr(quant_state\u001b[38;5;241m.\u001b[39mcode),\n",
      "\u001b[1;32m   1030\u001b[0m         get_ptr(A),\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1035\u001b[0m         _get_tensor_stream(A),\n",
      "\u001b[1;32m   1036\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/INF_CV/myenv/lib64/python3.9/site-packages/bitsandbytes/functional.py:457\u001b[0m, in \u001b[0;36mis_on_gpu\u001b[0;34m(tensors)\u001b[0m\n",
      "\u001b[1;32m    454\u001b[0m on_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;32m    455\u001b[0m gpu_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tensors:\n",
      "\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# NULL pointers and paged tensors are OK.\u001b[39;00m\n",
      "\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_paged\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[1;32m    460\u001b[0m         on_gpu \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mis_cuda\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range (10):\n",
    "    data = dataset[i]\n",
    "    text = data['text']\n",
    "    print(text)\n",
    "    summary = generate_summary(text)\n",
    "    print(\"Summary :\", summary)\n",
    "    print(len(summary.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le shard 0 est déjà traité, on passe au suivant.\n",
      "Le shard 1 est déjà traité, on passe au suivant.\n",
      "Le shard 2 est déjà traité, on passe au suivant.\n",
      "Le shard 3 est déjà traité, on passe au suivant.\n",
      "Le shard 4 est déjà traité, on passe au suivant.\n",
      "Le shard 5 est déjà traité, on passe au suivant.\n",
      "Le shard 6 est déjà traité, on passe au suivant.\n",
      "Le shard 7 est déjà traité, on passe au suivant.\n",
      "Le shard 8 est déjà traité, on passe au suivant.\n",
      "Le shard 9 est déjà traité, on passe au suivant.\n",
      "Le shard 10 est déjà traité, on passe au suivant.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d985d07b364e5d909fdeba84279528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7f46d386874a1e9ed9672f71a3391c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shard 11 traité et sauvegardé dans dataset_part_11.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae69d02b0ad645b1b0b327b2d3d24948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf63373997346b890ac1adc57987258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shard 12 traité et sauvegardé dans dataset_part_12.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3c69d3dfc24015b1340b3f7efe2301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab4622abaf84395ae63b13d0ef6dc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shard 13 traité et sauvegardé dans dataset_part_13.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c5045e8c634bbf96c1ca70ee93f997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377fde661085408ba4d8ea3d1a1b0ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shard 14 traité et sauvegardé dans dataset_part_14.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f872f060494549bb9707734b710c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0439d9f08ef542589bf9d2d9b12e1af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shard 15 traité et sauvegardé dans dataset_part_15.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f56b36fc3f4cf28f0134c17fd779a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc3baaa698944d797e7852fa2427d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shard 16 traité et sauvegardé dans dataset_part_16.json.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021830c841264b1b88bd729ec6679b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_shards = 20\n",
    "\n",
    "for i in range(num_shards):\n",
    "    output_file = f\"dataset_part_{i}.json\"\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Le shard {i} est déjà traité, on passe au suivant.\")\n",
    "        continue\n",
    "\n",
    "    shard = dataset.shard(num_shards=num_shards, index=i)\n",
    "    processed_shard = shard.map(lambda x: {\"summary\": generate_summary(x[\"text\"])})\n",
    "    processed_shard.to_json(output_file)\n",
    "    print(f\"Shard {i} traité et sauvegardé dans {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5dd35b469d48079aee468694eefb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbf34e5ee3147f9af45450ed4a03380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d2d5b078a24f9ca66dc6f9751690be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa762400488b4e8eb8b116e9ad39f4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff60f370c734a208766cc8f0254559d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56da3b73cdd64c91b42742afdae2a7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e95ef20729f47368a13f0b5243a01b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a805807291a45e0bfbfa300fc7d9be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dca117a42454c269976937ded1deeb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453e94905cfa4638bdeedd68167e5188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76888e2c9b2341a59a53ec792fd7275f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba22e4dc173492baa92cd11674c295e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbf0a2591cd4229a62e72ba1feedfa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59e4349d723457994ad477d5f92da39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc99cdb5b17a448abe2747cf1655f293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f7677cdd244ab08523bd84fea3fb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5ca9aed0294113965f60e41b77071d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54415523af7e49adb9e62d5e1d8464ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f71ae42e2e2420ab633392c01c940f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ccb60fe24d49a1a1dafdeabbb7333b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9e7cc08ed040da9e54b0975ae8d597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset fusionné et sauvegardé dans merged_dataset.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "num_shards = 20\n",
    "shard_files = []\n",
    "\n",
    "# Récupérer la liste des fichiers existants\n",
    "for i in range(num_shards):\n",
    "    file_path = f\"dataset_part_{i}.json\"\n",
    "    if os.path.exists(file_path):\n",
    "        shard_files.append(file_path)\n",
    "    else:\n",
    "        print(f\"Shard {i} introuvable.\")\n",
    "\n",
    "if not shard_files:\n",
    "    print(\"Aucun shard trouvé.\")\n",
    "else:\n",
    "    # Charger chaque shard dans une liste de Dataset\n",
    "    datasets_list = [load_dataset(\"json\", data_files=file_path)[\"train\"] for file_path in shard_files]\n",
    "    # Fusionner les datasets\n",
    "    merged_dataset = concatenate_datasets(datasets_list)\n",
    "    \n",
    "    # Sauvegarder le dataset fusionné dans un nouveau fichier JSON\n",
    "    merged_dataset.to_json(\"merged_dataset.json\")\n",
    "    print(\"Dataset fusionné et sauvegardé dans merged_dataset.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'token_length', 'summary'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abc4f3758cc47a18dbc96e8b7bc7d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "485812"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.to_json(\"summarization_dataset.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = 5000\n",
    "\n",
    "dataset_mlsum = load_dataset(\"mlsum\", \"fr\", cache_dir=\"/Data/gabriel-mercier/hf_datasets\")\n",
    "#dataset_wiki = load_dataset(\"wikipedia\", \"20220301.fr\", cache_dir=\"/Data/gabriel-mercier/hf_datasets\")\n",
    "\n",
    "dataset_init = dataset_mlsum['train'].shuffle(seed=42).select(range(5000)) \n",
    "dataset = dataset_init.select_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 5000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "tokenizer_llm = AutoTokenizer.from_pretrained(llm_name, \n",
    "                                          cache_dir=\"/Data/gabriel-mercier/hf_models\",\n",
    "                                          padding_side='left') #auto reggressive llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006d647859974c4fae18f50b4383df18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distibution')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_token_length(example):\n",
    "    tokens = tokenizer_llm(example[\"text\"], truncation=True, max_length=6000)[\"input_ids\"]\n",
    "    return {\"token_length\": len(tokens)}\n",
    "\n",
    "dataset_token = dataset.map(get_token_length)\n",
    "\n",
    "plt.hist(dataset_token[\"token_length\"], bins=100)\n",
    "plt.xlabel(\"Number of tokens\")\n",
    "plt.ylabel(\"Total\")\n",
    "plt.title(\"Distibution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2500\u001b[39m\n",
      "\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "max_length = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
