{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.13333333333333333,
  "eval_steps": 500,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0026666666666666666,
      "grad_norm": 1.7574734687805176,
      "learning_rate": 8e-05,
      "loss": 1.6701,
      "step": 2
    },
    {
      "epoch": 0.005333333333333333,
      "grad_norm": 1.419937014579773,
      "learning_rate": 0.00016,
      "loss": 1.6505,
      "step": 4
    },
    {
      "epoch": 0.008,
      "grad_norm": 1.4871494770050049,
      "learning_rate": 0.00019994532573409262,
      "loss": 1.7827,
      "step": 6
    },
    {
      "epoch": 0.010666666666666666,
      "grad_norm": 1.5883935689926147,
      "learning_rate": 0.00019950829025450114,
      "loss": 1.4761,
      "step": 8
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 1.7670766115188599,
      "learning_rate": 0.00019863613034027224,
      "loss": 1.5878,
      "step": 10
    },
    {
      "epoch": 0.016,
      "grad_norm": 1.665207862854004,
      "learning_rate": 0.0001973326597248006,
      "loss": 1.4756,
      "step": 12
    },
    {
      "epoch": 0.018666666666666668,
      "grad_norm": 1.6254605054855347,
      "learning_rate": 0.00019560357815343577,
      "loss": 1.421,
      "step": 14
    },
    {
      "epoch": 0.021333333333333333,
      "grad_norm": 2.146390438079834,
      "learning_rate": 0.0001934564464599461,
      "loss": 1.7197,
      "step": 16
    },
    {
      "epoch": 0.024,
      "grad_norm": 1.8970471620559692,
      "learning_rate": 0.00019090065350491626,
      "loss": 1.5699,
      "step": 18
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 1.9252407550811768,
      "learning_rate": 0.0001879473751206489,
      "loss": 1.7306,
      "step": 20
    },
    {
      "epoch": 0.029333333333333333,
      "grad_norm": 1.8707448244094849,
      "learning_rate": 0.00018460952524209355,
      "loss": 1.5834,
      "step": 22
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.7951781749725342,
      "learning_rate": 0.00018090169943749476,
      "loss": 1.2729,
      "step": 24
    },
    {
      "epoch": 0.034666666666666665,
      "grad_norm": 1.584314227104187,
      "learning_rate": 0.00017684011108568592,
      "loss": 1.4711,
      "step": 26
    },
    {
      "epoch": 0.037333333333333336,
      "grad_norm": 1.8571171760559082,
      "learning_rate": 0.00017244252047910892,
      "loss": 1.5365,
      "step": 28
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.5348780155181885,
      "learning_rate": 0.00016772815716257412,
      "loss": 1.3824,
      "step": 30
    },
    {
      "epoch": 0.042666666666666665,
      "grad_norm": 1.4360129833221436,
      "learning_rate": 0.0001627176358473537,
      "loss": 1.5191,
      "step": 32
    },
    {
      "epoch": 0.04533333333333334,
      "grad_norm": 1.7781236171722412,
      "learning_rate": 0.00015743286626829437,
      "loss": 1.3965,
      "step": 34
    },
    {
      "epoch": 0.048,
      "grad_norm": 1.567198634147644,
      "learning_rate": 0.00015189695737812152,
      "loss": 1.4912,
      "step": 36
    },
    {
      "epoch": 0.050666666666666665,
      "grad_norm": 1.479468584060669,
      "learning_rate": 0.0001461341162978688,
      "loss": 1.4534,
      "step": 38
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 1.512379765510559,
      "learning_rate": 0.00014016954246529696,
      "loss": 1.4729,
      "step": 40
    },
    {
      "epoch": 0.056,
      "grad_norm": 1.6940239667892456,
      "learning_rate": 0.00013402931744416433,
      "loss": 1.4862,
      "step": 42
    },
    {
      "epoch": 0.058666666666666666,
      "grad_norm": 1.6547861099243164,
      "learning_rate": 0.00012774029087618446,
      "loss": 1.321,
      "step": 44
    },
    {
      "epoch": 0.06133333333333333,
      "grad_norm": 1.6576571464538574,
      "learning_rate": 0.0001213299630743747,
      "loss": 1.5263,
      "step": 46
    },
    {
      "epoch": 0.064,
      "grad_norm": 1.785513162612915,
      "learning_rate": 0.0001148263647711842,
      "loss": 1.6175,
      "step": 48
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 1.805558443069458,
      "learning_rate": 0.00010825793454723325,
      "loss": 1.6434,
      "step": 50
    },
    {
      "epoch": 0.06933333333333333,
      "grad_norm": 1.6711127758026123,
      "learning_rate": 0.00010165339447663587,
      "loss": 1.5958,
      "step": 52
    },
    {
      "epoch": 0.072,
      "grad_norm": 1.6571753025054932,
      "learning_rate": 9.504162453267777e-05,
      "loss": 1.4605,
      "step": 54
    },
    {
      "epoch": 0.07466666666666667,
      "grad_norm": 1.2690268754959106,
      "learning_rate": 8.845153630304139e-05,
      "loss": 1.2489,
      "step": 56
    },
    {
      "epoch": 0.07733333333333334,
      "grad_norm": 1.5256078243255615,
      "learning_rate": 8.191194656678904e-05,
      "loss": 1.476,
      "step": 58
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.331050157546997,
      "learning_rate": 7.54514512859201e-05,
      "loss": 1.3191,
      "step": 60
    },
    {
      "epoch": 0.08266666666666667,
      "grad_norm": 1.4328804016113281,
      "learning_rate": 6.909830056250527e-05,
      "loss": 1.4298,
      "step": 62
    },
    {
      "epoch": 0.08533333333333333,
      "grad_norm": 1.4272122383117676,
      "learning_rate": 6.28802751081779e-05,
      "loss": 1.4753,
      "step": 64
    },
    {
      "epoch": 0.088,
      "grad_norm": 1.3650606870651245,
      "learning_rate": 5.6824564766150726e-05,
      "loss": 1.3276,
      "step": 66
    },
    {
      "epoch": 0.09066666666666667,
      "grad_norm": 1.3611154556274414,
      "learning_rate": 5.095764961694922e-05,
      "loss": 1.6011,
      "step": 68
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 1.4931395053863525,
      "learning_rate": 4.530518418775733e-05,
      "loss": 1.4476,
      "step": 70
    },
    {
      "epoch": 0.096,
      "grad_norm": 1.595491647720337,
      "learning_rate": 3.9891885271697496e-05,
      "loss": 1.4436,
      "step": 72
    },
    {
      "epoch": 0.09866666666666667,
      "grad_norm": 1.630702257156372,
      "learning_rate": 3.4741423847583134e-05,
      "loss": 1.4095,
      "step": 74
    },
    {
      "epoch": 0.10133333333333333,
      "grad_norm": 1.5063222646713257,
      "learning_rate": 2.9876321572751144e-05,
      "loss": 1.4544,
      "step": 76
    },
    {
      "epoch": 0.104,
      "grad_norm": 1.5507988929748535,
      "learning_rate": 2.5317852301584643e-05,
      "loss": 1.4064,
      "step": 78
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 1.44242525100708,
      "learning_rate": 2.1085949060360654e-05,
      "loss": 1.3592,
      "step": 80
    },
    {
      "epoch": 0.10933333333333334,
      "grad_norm": 1.49415123462677,
      "learning_rate": 1.7199116885197995e-05,
      "loss": 1.4145,
      "step": 82
    },
    {
      "epoch": 0.112,
      "grad_norm": 1.504475712776184,
      "learning_rate": 1.3674351904242611e-05,
      "loss": 1.5755,
      "step": 84
    },
    {
      "epoch": 0.11466666666666667,
      "grad_norm": 1.2780499458312988,
      "learning_rate": 1.0527067017923654e-05,
      "loss": 1.3881,
      "step": 86
    },
    {
      "epoch": 0.11733333333333333,
      "grad_norm": 1.3738621473312378,
      "learning_rate": 7.771024502261526e-06,
      "loss": 1.4502,
      "step": 88
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.6705249547958374,
      "learning_rate": 5.418275829936537e-06,
      "loss": 1.5029,
      "step": 90
    },
    {
      "epoch": 0.12266666666666666,
      "grad_norm": 1.3008922338485718,
      "learning_rate": 3.4791089722651436e-06,
      "loss": 1.3456,
      "step": 92
    },
    {
      "epoch": 0.12533333333333332,
      "grad_norm": 1.8090674877166748,
      "learning_rate": 1.9620034125190644e-06,
      "loss": 1.3681,
      "step": 94
    },
    {
      "epoch": 0.128,
      "grad_norm": 1.444364309310913,
      "learning_rate": 8.735930673024806e-07,
      "loss": 1.5656,
      "step": 96
    },
    {
      "epoch": 0.13066666666666665,
      "grad_norm": 1.4463634490966797,
      "learning_rate": 2.1863727812254653e-07,
      "loss": 1.3437,
      "step": 98
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 1.5368224382400513,
      "learning_rate": 0.0,
      "loss": 1.348,
      "step": 100
    }
  ],
  "logging_steps": 2,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1038089852236800.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
