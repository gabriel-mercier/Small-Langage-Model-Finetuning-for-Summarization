{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import evaluate\n",
    "from transformers import DataCollatorForSeq2Seq, AutoTokenizer, BitsAndBytesConfig, AutoModelForSeq2SeqLM\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import prepare_prompt, print_trainable_parameters\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split = load_from_disk('dataset_split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"/Data/gabriel-mercier/slm_models\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-base\", cache_dir=cache_dir)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True, \n",
    "                                bnb_4bit_use_double_quant=True,\n",
    "                                bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                bnb_4bit_quant_type='nf4',\n",
    "                            )\n",
    "model_raw = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-base\", \n",
    "                                              cache_dir=cache_dir,\n",
    "                                              trust_remote_code=True,\n",
    "                                              quantization_config=bnb_config,\n",
    "                                              device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3538944 || all params: 155663616 || trainable%: 2.273456117067202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trainable params: 3538944 || all params: 155663616 || trainable%: 2.273456117067202'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_finetune = True\n",
    "r = 8\n",
    "if lora_finetune:\n",
    "    lora_config = LoraConfig(r=r, \n",
    "                            lora_alpha=2*r,\n",
    "                            target_modules=[\"q\", \"k\", \"v\", \"o\"],\n",
    "                            lora_dropout=0.05,\n",
    "                            bias='none',\n",
    "                            task_type=\"SEQ_2_SEQ_LM\")\n",
    "\n",
    "    model = get_peft_model(model_raw, lora_config)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 14155776 || all params: 166280448 || trainable%: 8.513193325050459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trainable params: 14155776 || all params: 166280448 || trainable%: 8.513193325050459'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_config = model.generation_config\n",
    "generation_config.max_new_tokens = 200\n",
    "generation_config.temperature = 0.7\n",
    "generation_config.top_p = 0.7\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "generation_config.do_sample = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROMPT ===\n",
      "R√©sume pr√©cis√©ment le texte suivant en fran√ßais en 100 mots maximum. Concentre-toi sur les points essentiels sans ajouter d'opinions ni de commentaires. √âvite les phrases inutiles et reformule les id√©es clairement.\n",
      "\n",
      "Texte :\n",
      "Le 24 ao√ªt 1991, des Moscovites accompagnent les d√©pouilles des trois victimes du putsch, tu√©es trois jours plus t√¥t. Gueorgui Pinkhassov/Magnum C‚Äô√©tait encore le temps des vacances, du repos dans les datchas. Le major-colonel du KGB Valeri Chiria√Øev dormait dans la sienne, une bicoque sans eau, quelque part dans un trou perdu de la r√©gion de Iaroslav, quand la ¬´ bo√Æte ¬ª fix√©e au mur s‚Äôest mise √† gr√©siller. ¬´ On ne savait m√™me plus si ce machin marchait encore ¬ª, raconte-t-il. L‚Äôantique haut-parleur avait √©t√© install√© dans toutes les demeures sovi√©tiques pour pr√©venir d‚Äôune guerre nucl√©aire. Le message contenait aussi un code secret pour toutes les forces de s√©curit√©. Et ce matin du 19 ao√ªt 1991, il y a vingt-cinq ans, Valeri Chiria√Øev d√©couvre, stup√©fait, qu‚Äôun coup d‚ÄôEtat est en cours √† Moscou, men√© par les plus conservateurs des dirigeants. L‚Äôhomme de la glasnost Oppos√©s √† la signature, pr√©vue le lendemain, d‚Äôun nouvel accord d‚Äôassociation entre les membres d‚Äôune URSS r√©form√©e et rebaptis√©e ¬´ Union des r√©publiques socialistes souveraines ¬ª et non plus ¬´ sovi√©tiques ¬ª, huit hauts dignitaires tentent d‚Äô√©carter du pouvoir Mikha√Øl Gorbatchev, l‚Äôhomme de la glasnost (la transparence), ¬´ retenu ¬ª dans sa r√©sidence d‚Äô√©t√©, √† Foros, en Crim√©e. L‚Äôinitiative tourne court : en cinq jours, les conspirateurs r√©unis dans un √©ph√©m√®re Comit√© pour l‚Äô√©tat d‚Äôurgence, dont faisait partie Vladimir Krioutchkov, le patron du KGB, sont arr√™t√©s. Le putsch des nostalgiques d‚Äôun pouvoir communiste fort a √©chou√©. Ces √©v√©nements vont pr√©cipiter la chute de l‚Äôempire. Le Parti communiste de l‚ÄôUnion sovi√©tique (PCUS) est dissous, la statue de ¬≠F√©lix Dzerjinski, le fondateur de la Tch√©ka, la police bolchevique √† l‚Äôorigine du KGB, d√©boulonn√©e, et quatre mois plus tard, le 26 d√©cembre 1991, √† Minsk, la Russie, la Bi√©lorussie et l‚ÄôUkraine signent officiellement l‚Äôacte de d√©c√®s de l‚ÄôURSS. M√©dus√©, le monde assiste √† l‚Äôeffondrement sans violence d‚Äôune des grandes puissances de l‚Äôapr√®s-guerre, et √† l‚Äô√©croulement d‚Äôun r√©gime totalitaire. Article r√©serv√© √† nos abonn√©s Lire aussi Dans la Russie de Poutine, l‚Äôanniversaire ignor√© du putsch rat√© de 1991 Le vingt-cinqui√®me anniversaire du putsch rat√© n‚Äôa donn√© lieu √† aucune r√©jouissance en Russie. Aucune comm√©moration officielle n‚Äôa √©t√© organis√©e, ni m√™me un discours prononc√©, bien que Vladimir Poutine tire directement son pouvoir de ces jours fi√©vreux o√π tout a bascul√©. Si Boris Eltsine n‚Äô√©tait pas mont√© sur un char pour haranguer la foule et s‚Äôopposer aux putschistes devant le parlement de la ¬≠R√©publique socialiste sovi√©tique de Russie, l‚Äôactuel pr√©sident russe n‚Äôaurait sans doute jamais acc√©d√© √† la plus haute marche de l‚ÄôEtat. Un quart de si√®cle plus tard, c‚Äôest en Crim√©e, la p√©ninsule ukrainienne annex√©e en 2014, que Vladimir Poutine a choisi de se rendre √† la date du 19 ao√ªt.\n",
      "\n",
      "R√©sum√© concis et structur√© (100 mots maximum) :\n",
      "=== GENERATED SUMMARY ===\n",
      "<extra_id_0> √† l‚Äôint√©rieur.\n",
      "3\n",
      "=== LABEL SUMMARY ===\n",
      "Le 19 ao√ªt 1991, huit conservateurs tentent un coup d'√âtat contre Mikha√Øl Gorbatchev, retenue en Crim√©e. Ils s'opposent √† un nouvel accord r√©formateur. Apr√®s 5 jours, les putschistes sont arr√™t√©s. Cet √©chec pr√©cipite la chute de l'URSS : dissolution du PCUS, effondrement du r√©gime totalitaire. Le 26 d√©cembre 1991, l'URSS dispara√Æt officiellement. En 2016, Vladimir Poutine, qui tire son pouvoir de cet √©pisode, c√©l√®bre le 25e anniversaire en Crim√©e, annex√©e en 2014.\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "assistant_start = \"R√©sum√© concis et structur√© (100 mots maximum) :\"\n",
    "summary_data = dataset_split['train'][1]['summary']\n",
    "prompt = prepare_prompt(dataset_split['train'][1], summary_included=False)\n",
    "print('=== PROMPT ===')\n",
    "print(prompt)\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "start_index = prediction.find(assistant_start)\n",
    "if start_index != -1:\n",
    "    response_start = start_index + len(assistant_start)\n",
    "else:\n",
    "    response_start = -1 \n",
    "\n",
    "print(\"=== GENERATED SUMMARY ===\")\n",
    "print(prediction[response_start+1:])\n",
    "print(len(prediction[response_start+1:].split()))\n",
    "\n",
    "print(\"=== LABEL SUMMARY ===\")\n",
    "print(summary_data)\n",
    "print(len(summary_data.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    labels = tokenizer(examples[\"summary\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad533dd8abae4bffaf0428247e9f2d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2655 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e552d261d384f7c9912ea9e46ba5a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/885 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 2655\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 885\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_train = dataset_split[\"train\"].map(preprocess_function)\n",
    "dataset_val = dataset_split[\"validation\"].map(preprocess_function)\n",
    "\n",
    "dataset_train = dataset_train.remove_columns([\"text\", \"summary\"])\n",
    "dataset_val = dataset_val.remove_columns([\"text\", \"summary\"])\n",
    "\n",
    "print(dataset_train)\n",
    "print(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a data collator for seq2seq tasks\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2022/gabriel.mercier/INF_CV/myenv/lib64/python3.9/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_train.select(range(500)),\n",
    "    eval_dataset=dataset_val.select(range(10)),\n",
    "    args=training_args,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 05:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.697000</td>\n",
       "      <td>2.618326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.987600</td>\n",
       "      <td>2.571890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.523800</td>\n",
       "      <td>2.567580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=3.498820992787679, metrics={'train_runtime': 337.177, 'train_samples_per_second': 4.449, 'train_steps_per_second': 1.112, 'total_flos': 453719162880000.0, 'train_loss': 3.498820992787679, 'epoch': 3.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./encoder_decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./autoregressive_model\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROMPT ===\n",
      "R√©sume pr√©cis√©ment le texte suivant en fran√ßais en 100 mots maximum. Concentre-toi sur les points essentiels sans ajouter d'opinions ni de commentaires. √âvite les phrases inutiles et reformule les id√©es clairement.\n",
      "\n",
      "Texte :\n",
      "Le 24 ao√ªt 1991, des Moscovites accompagnent les d√©pouilles des trois victimes du putsch, tu√©es trois jours plus t√¥t. Gueorgui Pinkhassov/Magnum C‚Äô√©tait encore le temps des vacances, du repos dans les datchas. Le major-colonel du KGB Valeri Chiria√Øev dormait dans la sienne, une bicoque sans eau, quelque part dans un trou perdu de la r√©gion de Iaroslav, quand la ¬´ bo√Æte ¬ª fix√©e au mur s‚Äôest mise √† gr√©siller. ¬´ On ne savait m√™me plus si ce machin marchait encore ¬ª, raconte-t-il. L‚Äôantique haut-parleur avait √©t√© install√© dans toutes les demeures sovi√©tiques pour pr√©venir d‚Äôune guerre nucl√©aire. Le message contenait aussi un code secret pour toutes les forces de s√©curit√©. Et ce matin du 19 ao√ªt 1991, il y a vingt-cinq ans, Valeri Chiria√Øev d√©couvre, stup√©fait, qu‚Äôun coup d‚ÄôEtat est en cours √† Moscou, men√© par les plus conservateurs des dirigeants. L‚Äôhomme de la glasnost Oppos√©s √† la signature, pr√©vue le lendemain, d‚Äôun nouvel accord d‚Äôassociation entre les membres d‚Äôune URSS r√©form√©e et rebaptis√©e ¬´ Union des r√©publiques socialistes souveraines ¬ª et non plus ¬´ sovi√©tiques ¬ª, huit hauts dignitaires tentent d‚Äô√©carter du pouvoir Mikha√Øl Gorbatchev, l‚Äôhomme de la glasnost (la transparence), ¬´ retenu ¬ª dans sa r√©sidence d‚Äô√©t√©, √† Foros, en Crim√©e. L‚Äôinitiative tourne court : en cinq jours, les conspirateurs r√©unis dans un √©ph√©m√®re Comit√© pour l‚Äô√©tat d‚Äôurgence, dont faisait partie Vladimir Krioutchkov, le patron du KGB, sont arr√™t√©s. Le putsch des nostalgiques d‚Äôun pouvoir communiste fort a √©chou√©. Ces √©v√©nements vont pr√©cipiter la chute de l‚Äôempire. Le Parti communiste de l‚ÄôUnion sovi√©tique (PCUS) est dissous, la statue de ¬≠F√©lix Dzerjinski, le fondateur de la Tch√©ka, la police bolchevique √† l‚Äôorigine du KGB, d√©boulonn√©e, et quatre mois plus tard, le 26 d√©cembre 1991, √† Minsk, la Russie, la Bi√©lorussie et l‚ÄôUkraine signent officiellement l‚Äôacte de d√©c√®s de l‚ÄôURSS. M√©dus√©, le monde assiste √† l‚Äôeffondrement sans violence d‚Äôune des grandes puissances de l‚Äôapr√®s-guerre, et √† l‚Äô√©croulement d‚Äôun r√©gime totalitaire. Article r√©serv√© √† nos abonn√©s Lire aussi Dans la Russie de Poutine, l‚Äôanniversaire ignor√© du putsch rat√© de 1991 Le vingt-cinqui√®me anniversaire du putsch rat√© n‚Äôa donn√© lieu √† aucune r√©jouissance en Russie. Aucune comm√©moration officielle n‚Äôa √©t√© organis√©e, ni m√™me un discours prononc√©, bien que Vladimir Poutine tire directement son pouvoir de ces jours fi√©vreux o√π tout a bascul√©. Si Boris Eltsine n‚Äô√©tait pas mont√© sur un char pour haranguer la foule et s‚Äôopposer aux putschistes devant le parlement de la ¬≠R√©publique socialiste sovi√©tique de Russie, l‚Äôactuel pr√©sident russe n‚Äôaurait sans doute jamais acc√©d√© √† la plus haute marche de l‚ÄôEtat. Un quart de si√®cle plus tard, c‚Äôest en Crim√©e, la p√©ninsule ukrainienne annex√©e en 2014, que Vladimir Poutine a choisi de se rendre √† la date du 19 ao√ªt.\n",
      "\n",
      "R√©sum√© concis et structur√© (100 mots maximum) :\n",
      "=== GENERATED SUMMARY ===\n",
      "<extra_id_0> de l‚ÄôURSS. Texte : <extra_id_1> le texte en fran√ßais. Texte en fran√ßais. Texte en fran√ßais. L‚Äôhistoire..  <extra_id_2>...... .. .. . . . . . . . . . . . . . . . . . / ... / / / ' ' / ' ' l  s s r r s n s t s l'  <extra_id_40> l '  <extra_id_41>  <extra_id_41>  <extra_id_24> '  <extra_id_41> T l '  <extra_id_41>  <extra_id_39> <extra_id_39>  <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39>\n",
      "122\n",
      "=== LABEL SUMMARY ===\n",
      "Le 19 ao√ªt 1991, huit conservateurs tentent un coup d'√âtat contre Mikha√Øl Gorbatchev, retenue en Crim√©e. Ils s'opposent √† un nouvel accord r√©formateur. Apr√®s 5 jours, les putschistes sont arr√™t√©s. Cet √©chec pr√©cipite la chute de l'URSS : dissolution du PCUS, effondrement du r√©gime totalitaire. Le 26 d√©cembre 1991, l'URSS dispara√Æt officiellement. En 2016, Vladimir Poutine, qui tire son pouvoir de cet √©pisode, c√©l√®bre le 25e anniversaire en Crim√©e, annex√©e en 2014.\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "assistant_start = \"R√©sum√© concis et structur√© (100 mots maximum) :\"\n",
    "summary_data = dataset_split['train'][1]['summary']\n",
    "prompt = prepare_prompt(dataset_split['train'][1], summary_included=False)\n",
    "print('=== PROMPT ===')\n",
    "print(prompt)\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "start_index = prediction.find(assistant_start)\n",
    "if start_index != -1:\n",
    "    response_start = start_index + len(assistant_start)\n",
    "else:\n",
    "    response_start = -1 \n",
    "\n",
    "print(\"=== GENERATED SUMMARY ===\")\n",
    "print(prediction[response_start+1:])\n",
    "print(len(prediction[response_start+1:].split()))\n",
    "\n",
    "print(\"=== LABEL SUMMARY ===\")\n",
    "print(summary_data)\n",
    "print(len(summary_data.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = dataset_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bert_score = evaluate.load(\"bertscore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset):\n",
    "    summaries = [data_point['summary'] for data_point in dataset]\n",
    "    predictions = []\n",
    "\n",
    "    for data_point in tqdm(dataset):\n",
    "        prompt = prepare_prompt(data_point, summary_included=False)\n",
    "        encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        with torch.inference_mode():\n",
    "            output = model.generate(\n",
    "                input_ids=encoding.input_ids,\n",
    "                attention_mask=encoding.attention_mask,\n",
    "                generation_config=generation_config,\n",
    "            )\n",
    "            \n",
    "        prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        response_start = prediction.find(assistant_start)\n",
    "        predictions.append(prediction[response_start:])\n",
    "\n",
    "    rouge_results = rouge.compute(predictions=predictions, references=summaries)\n",
    "    bert_results = bert_score.compute(predictions=predictions, references=summaries, lang=\"fr\")\n",
    "\n",
    "    bert_precision = np.mean(bert_results['precision'])\n",
    "    bert_recall = np.mean(bert_results['recall'])\n",
    "    bert_f1 = np.mean(bert_results['f1'])\n",
    "\n",
    "    print(f\"BERTScore - Precision: {bert_precision:.4f}, Recall: {bert_recall:.4f}, F1: {bert_f1:.4f}\")\n",
    "    print(f\"ROUGEScores - {rouge_results}\")\n",
    "    print('\\n')\n",
    "    \n",
    "    return rouge_results, {'Precision':bert_precision, 'Recall':bert_recall, 'F1':bert_f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_1 = dataset_test.select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:23<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.5700, Recall: 0.4051, F1: 0.4732\n",
      "ROUGEScores - {'rouge1': np.float64(0.0), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.0), 'rougeLsum': np.float64(0.0)}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "rouges_results_finetune, bert_results_finetune = evaluate_model(model, dataset_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_finetune = {\n",
    "    \"rouge\": rouges_results_finetune,\n",
    "    \"bert\": bert_results_finetune\n",
    "}\n",
    "\n",
    "with open(\"mt5_evaluation_results_finetune.json\", \"w\") as f:\n",
    "    json.dump(results_finetune, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:20<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.6403, Recall: 0.4503, F1: 0.5285\n",
      "ROUGEScores - {'rouge1': np.float64(0.0), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.0), 'rougeLsum': np.float64(0.0)}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rouges_results_raw, bert_results_raw = evaluate_model(model_raw, dataset_test_1)\n",
    "\n",
    "results_raw = {\n",
    "    \"rouge\": rouges_results_raw,\n",
    "    \"bert\": bert_results_raw\n",
    "}\n",
    "\n",
    "with open(\"mt5_evaluation_results_raw.json\", \"w\") as f:\n",
    "    json.dump(results_raw, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.9.21)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
