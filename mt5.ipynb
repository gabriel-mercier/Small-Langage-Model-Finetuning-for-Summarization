{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import evaluate\n",
    "from transformers import DataCollatorForSeq2Seq, AutoTokenizer, BitsAndBytesConfig, AutoModelForSeq2SeqLM\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import prepare_prompt, print_trainable_parameters\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'summary'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_raw = load_dataset('json', data_files='dataset_llm_generated.json')\n",
    "dataset = dataset_raw.select_columns([\"text\", \"summary\"])\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'summary'],\n",
      "        num_rows: 4426\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset['train'] = dataset['train'].filter(lambda x: len(x['text'].split()) <= 2500)\n",
    "dataset['train'] = dataset['train'].filter(lambda x: len(x['text'].split()) >= 200)\n",
    "dataset['train'] = dataset['train'].filter(lambda x: len(x['summary'].split()) >= 40)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'summary'],\n",
      "        num_rows: 2655\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'summary'],\n",
      "        num_rows: 885\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'summary'],\n",
      "        num_rows: 886\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "split_train_temp = dataset[\"train\"].train_test_split(test_size=0.4, seed=42)\n",
    "\n",
    "split_valid_test = split_train_temp[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "dataset_split = DatasetDict({\n",
    "    \"train\": split_train_temp[\"train\"],        \n",
    "    \"validation\": split_valid_test[\"train\"],      \n",
    "    \"test\": split_valid_test[\"test\"]              \n",
    "})\n",
    "\n",
    "print(dataset_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/users/eleves-b/2022/gabriel.mercier/INF_CV/myenv/lib64/python3.9/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cache_dir = \"/Data/gabriel-mercier/slm_models\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-base\", cache_dir=cache_dir)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True, \n",
    "                                bnb_4bit_use_double_quant=True,\n",
    "                                bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                bnb_4bit_quant_type='nf4',\n",
    "                            )\n",
    "model_raw = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-base\", \n",
    "                                              cache_dir=cache_dir,\n",
    "                                              trust_remote_code=True,\n",
    "                                              quantization_config=bnb_config,\n",
    "                                              device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_finetune = True\n",
    "\n",
    "if lora_finetune:\n",
    "    lora_config = LoraConfig(r=16, \n",
    "                            lora_alpha=32,\n",
    "                            target_modules=[\"q\", \"k\", \"v\", \"o\"],\n",
    "                            lora_dropout=0.05,\n",
    "                            bias='none',\n",
    "                            task_type=\"SEQ_2_SEQ_LM\")\n",
    "\n",
    "    model = get_peft_model(model_raw, lora_config)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3538944 || all params: 505724160 || trainable%: 0.6997775229880258\n"
     ]
    }
   ],
   "source": [
    "generation_config = model.generation_config\n",
    "generation_config.max_new_tokens = 200\n",
    "generation_config.temperature = 0.7\n",
    "generation_config.top_p = 0.7\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "generation_config.do_sample = True\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROMPT ===\n",
      "Résume précisément le texte suivant en français en 100 mots maximum. Concentre-toi sur les points essentiels sans ajouter d'opinions ni de commentaires. Évite les phrases inutiles et reformule les idées clairement.\n",
      "\n",
      "Texte :\n",
      "Le 24 août 1991, des Moscovites accompagnent les dépouilles des trois victimes du putsch, tuées trois jours plus tôt. Gueorgui Pinkhassov/Magnum C’était encore le temps des vacances, du repos dans les datchas. Le major-colonel du KGB Valeri Chiriaïev dormait dans la sienne, une bicoque sans eau, quelque part dans un trou perdu de la région de Iaroslav, quand la « boîte » fixée au mur s’est mise à grésiller. « On ne savait même plus si ce machin marchait encore », raconte-t-il. L’antique haut-parleur avait été installé dans toutes les demeures soviétiques pour prévenir d’une guerre nucléaire. Le message contenait aussi un code secret pour toutes les forces de sécurité. Et ce matin du 19 août 1991, il y a vingt-cinq ans, Valeri Chiriaïev découvre, stupéfait, qu’un coup d’Etat est en cours à Moscou, mené par les plus conservateurs des dirigeants. L’homme de la glasnost Opposés à la signature, prévue le lendemain, d’un nouvel accord d’association entre les membres d’une URSS réformée et rebaptisée « Union des républiques socialistes souveraines » et non plus « soviétiques », huit hauts dignitaires tentent d’écarter du pouvoir Mikhaïl Gorbatchev, l’homme de la glasnost (la transparence), « retenu » dans sa résidence d’été, à Foros, en Crimée. L’initiative tourne court : en cinq jours, les conspirateurs réunis dans un éphémère Comité pour l’état d’urgence, dont faisait partie Vladimir Krioutchkov, le patron du KGB, sont arrêtés. Le putsch des nostalgiques d’un pouvoir communiste fort a échoué. Ces événements vont précipiter la chute de l’empire. Le Parti communiste de l’Union soviétique (PCUS) est dissous, la statue de ­Félix Dzerjinski, le fondateur de la Tchéka, la police bolchevique à l’origine du KGB, déboulonnée, et quatre mois plus tard, le 26 décembre 1991, à Minsk, la Russie, la Biélorussie et l’Ukraine signent officiellement l’acte de décès de l’URSS. Médusé, le monde assiste à l’effondrement sans violence d’une des grandes puissances de l’après-guerre, et à l’écroulement d’un régime totalitaire. Article réservé à nos abonnés Lire aussi Dans la Russie de Poutine, l’anniversaire ignoré du putsch raté de 1991 Le vingt-cinquième anniversaire du putsch raté n’a donné lieu à aucune réjouissance en Russie. Aucune commémoration officielle n’a été organisée, ni même un discours prononcé, bien que Vladimir Poutine tire directement son pouvoir de ces jours fiévreux où tout a basculé. Si Boris Eltsine n’était pas monté sur un char pour haranguer la foule et s’opposer aux putschistes devant le parlement de la ­République socialiste soviétique de Russie, l’actuel président russe n’aurait sans doute jamais accédé à la plus haute marche de l’Etat. Un quart de siècle plus tard, c’est en Crimée, la péninsule ukrainienne annexée en 2014, que Vladimir Poutine a choisi de se rendre à la date du 19 août.\n",
      "\n",
      "Résumé concis et structuré (100 mots maximum) :\n",
      "=== GENERATED SUMMARY ===\n",
      "<extra_id_0> à l’intérieur.\n",
      "3\n",
      "=== LABEL SUMMARY ===\n",
      "Le 19 août 1991, huit conservateurs tentent un coup d'État contre Mikhaïl Gorbatchev, retenue en Crimée. Ils s'opposent à un nouvel accord réformateur. Après 5 jours, les putschistes sont arrêtés. Cet échec précipite la chute de l'URSS : dissolution du PCUS, effondrement du régime totalitaire. Le 26 décembre 1991, l'URSS disparaît officiellement. En 2016, Vladimir Poutine, qui tire son pouvoir de cet épisode, célèbre le 25e anniversaire en Crimée, annexée en 2014.\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "assistant_start = \"Résumé concis et structuré (100 mots maximum) :\"\n",
    "summary_data = dataset_split['train'][1]['summary']\n",
    "prompt = prepare_prompt(dataset_split['train'][1], summary_included=False)\n",
    "print('=== PROMPT ===')\n",
    "print(prompt)\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "start_index = prediction.find(assistant_start)\n",
    "if start_index != -1:\n",
    "    response_start = start_index + len(assistant_start)\n",
    "else:\n",
    "    response_start = -1 \n",
    "\n",
    "print(\"=== GENERATED SUMMARY ===\")\n",
    "print(prediction[response_start+1:])\n",
    "print(len(prediction[response_start+1:].split()))\n",
    "\n",
    "print(\"=== LABEL SUMMARY ===\")\n",
    "print(summary_data)\n",
    "print(len(summary_data.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    labels = tokenizer(examples[\"summary\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad533dd8abae4bffaf0428247e9f2d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2655 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e552d261d384f7c9912ea9e46ba5a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/885 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 2655\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 885\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_train = dataset_split[\"train\"].map(preprocess_function)\n",
    "dataset_val = dataset_split[\"validation\"].map(preprocess_function)\n",
    "\n",
    "dataset_train = dataset_train.remove_columns([\"text\", \"summary\"])\n",
    "dataset_val = dataset_val.remove_columns([\"text\", \"summary\"])\n",
    "\n",
    "print(dataset_train)\n",
    "print(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a data collator for seq2seq tasks\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2022/gabriel.mercier/INF_CV/myenv/lib64/python3.9/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=1,\n",
    "    output_dir=\"./mt5_finetuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_train.select(range(50)),\n",
    "    eval_dataset=dataset_val.select(range(10)),\n",
    "    args=training_args,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:34, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.760200</td>\n",
       "      <td>2.792951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.445600</td>\n",
       "      <td>2.770083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36, training_loss=3.6252304216225943, metrics={'train_runtime': 35.0735, 'train_samples_per_second': 4.277, 'train_steps_per_second': 1.026, 'total_flos': 42347121868800.0, 'train_loss': 3.6252304216225943, 'epoch': 2.8})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./encoder_decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./autoregressive_model\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROMPT ===\n",
      "Résume précisément le texte suivant en français en 100 mots maximum. Concentre-toi sur les points essentiels sans ajouter d'opinions ni de commentaires. Évite les phrases inutiles et reformule les idées clairement.\n",
      "\n",
      "Texte :\n",
      "Le 24 août 1991, des Moscovites accompagnent les dépouilles des trois victimes du putsch, tuées trois jours plus tôt. Gueorgui Pinkhassov/Magnum C’était encore le temps des vacances, du repos dans les datchas. Le major-colonel du KGB Valeri Chiriaïev dormait dans la sienne, une bicoque sans eau, quelque part dans un trou perdu de la région de Iaroslav, quand la « boîte » fixée au mur s’est mise à grésiller. « On ne savait même plus si ce machin marchait encore », raconte-t-il. L’antique haut-parleur avait été installé dans toutes les demeures soviétiques pour prévenir d’une guerre nucléaire. Le message contenait aussi un code secret pour toutes les forces de sécurité. Et ce matin du 19 août 1991, il y a vingt-cinq ans, Valeri Chiriaïev découvre, stupéfait, qu’un coup d’Etat est en cours à Moscou, mené par les plus conservateurs des dirigeants. L’homme de la glasnost Opposés à la signature, prévue le lendemain, d’un nouvel accord d’association entre les membres d’une URSS réformée et rebaptisée « Union des républiques socialistes souveraines » et non plus « soviétiques », huit hauts dignitaires tentent d’écarter du pouvoir Mikhaïl Gorbatchev, l’homme de la glasnost (la transparence), « retenu » dans sa résidence d’été, à Foros, en Crimée. L’initiative tourne court : en cinq jours, les conspirateurs réunis dans un éphémère Comité pour l’état d’urgence, dont faisait partie Vladimir Krioutchkov, le patron du KGB, sont arrêtés. Le putsch des nostalgiques d’un pouvoir communiste fort a échoué. Ces événements vont précipiter la chute de l’empire. Le Parti communiste de l’Union soviétique (PCUS) est dissous, la statue de ­Félix Dzerjinski, le fondateur de la Tchéka, la police bolchevique à l’origine du KGB, déboulonnée, et quatre mois plus tard, le 26 décembre 1991, à Minsk, la Russie, la Biélorussie et l’Ukraine signent officiellement l’acte de décès de l’URSS. Médusé, le monde assiste à l’effondrement sans violence d’une des grandes puissances de l’après-guerre, et à l’écroulement d’un régime totalitaire. Article réservé à nos abonnés Lire aussi Dans la Russie de Poutine, l’anniversaire ignoré du putsch raté de 1991 Le vingt-cinquième anniversaire du putsch raté n’a donné lieu à aucune réjouissance en Russie. Aucune commémoration officielle n’a été organisée, ni même un discours prononcé, bien que Vladimir Poutine tire directement son pouvoir de ces jours fiévreux où tout a basculé. Si Boris Eltsine n’était pas monté sur un char pour haranguer la foule et s’opposer aux putschistes devant le parlement de la ­République socialiste soviétique de Russie, l’actuel président russe n’aurait sans doute jamais accédé à la plus haute marche de l’Etat. Un quart de siècle plus tard, c’est en Crimée, la péninsule ukrainienne annexée en 2014, que Vladimir Poutine a choisi de se rendre à la date du 19 août.\n",
      "\n",
      "Résumé concis et structuré (100 mots maximum) :\n",
      "=== GENERATED SUMMARY ===\n",
      "<extra_id_0> de l’URSS. Texte : <extra_id_1> le texte en français. Texte en français. Texte en français. L’histoire..  <extra_id_2>...... .. .. . . . . . . . . . . . . . . . . . / ... / / / ' ' / ' ' l  s s r r s n s t s l'  <extra_id_40> l '  <extra_id_41>  <extra_id_41>  <extra_id_24> '  <extra_id_41> T l '  <extra_id_41>  <extra_id_39> <extra_id_39>  <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39> <extra_id_39>\n",
      "122\n",
      "=== LABEL SUMMARY ===\n",
      "Le 19 août 1991, huit conservateurs tentent un coup d'État contre Mikhaïl Gorbatchev, retenue en Crimée. Ils s'opposent à un nouvel accord réformateur. Après 5 jours, les putschistes sont arrêtés. Cet échec précipite la chute de l'URSS : dissolution du PCUS, effondrement du régime totalitaire. Le 26 décembre 1991, l'URSS disparaît officiellement. En 2016, Vladimir Poutine, qui tire son pouvoir de cet épisode, célèbre le 25e anniversaire en Crimée, annexée en 2014.\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "assistant_start = \"Résumé concis et structuré (100 mots maximum) :\"\n",
    "summary_data = dataset_split['train'][1]['summary']\n",
    "prompt = prepare_prompt(dataset_split['train'][1], summary_included=False)\n",
    "print('=== PROMPT ===')\n",
    "print(prompt)\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=encoding.input_ids,\n",
    "        attention_mask=encoding.attention_mask,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "start_index = prediction.find(assistant_start)\n",
    "if start_index != -1:\n",
    "    response_start = start_index + len(assistant_start)\n",
    "else:\n",
    "    response_start = -1 \n",
    "\n",
    "print(\"=== GENERATED SUMMARY ===\")\n",
    "print(prediction[response_start+1:])\n",
    "print(len(prediction[response_start+1:].split()))\n",
    "\n",
    "print(\"=== LABEL SUMMARY ===\")\n",
    "print(summary_data)\n",
    "print(len(summary_data.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = dataset_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bert_score = evaluate.load(\"bertscore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset):\n",
    "    summaries = [data_point['summary'] for data_point in dataset]\n",
    "    predictions = []\n",
    "\n",
    "    for data_point in tqdm(dataset):\n",
    "        prompt = prepare_prompt(data_point, summary_included=False)\n",
    "        encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        with torch.inference_mode():\n",
    "            output = model.generate(\n",
    "                input_ids=encoding.input_ids,\n",
    "                attention_mask=encoding.attention_mask,\n",
    "                generation_config=generation_config,\n",
    "            )\n",
    "            \n",
    "        prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        response_start = prediction.find(assistant_start)\n",
    "        predictions.append(prediction[response_start:])\n",
    "\n",
    "    rouge_results = rouge.compute(predictions=predictions, references=summaries)\n",
    "    bert_results = bert_score.compute(predictions=predictions, references=summaries, lang=\"fr\")\n",
    "\n",
    "    bert_precision = np.mean(bert_results['precision'])\n",
    "    bert_recall = np.mean(bert_results['recall'])\n",
    "    bert_f1 = np.mean(bert_results['f1'])\n",
    "\n",
    "    print(f\"BERTScore - Precision: {bert_precision:.4f}, Recall: {bert_recall:.4f}, F1: {bert_f1:.4f}\")\n",
    "    print(f\"ROUGEScores - {rouge_results}\")\n",
    "    print('\\n')\n",
    "    \n",
    "    return rouge_results, {'Precision':bert_precision, 'Recall':bert_recall, 'F1':bert_f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_1 = dataset_test.select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:23<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.5700, Recall: 0.4051, F1: 0.4732\n",
      "ROUGEScores - {'rouge1': np.float64(0.0), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.0), 'rougeLsum': np.float64(0.0)}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "rouges_results_finetune, bert_results_finetune = evaluate_model(model, dataset_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_finetune = {\n",
    "    \"rouge\": rouges_results_finetune,\n",
    "    \"bert\": bert_results_finetune\n",
    "}\n",
    "\n",
    "with open(\"mt5_evaluation_results_finetune.json\", \"w\") as f:\n",
    "    json.dump(results_finetune, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:20<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.6403, Recall: 0.4503, F1: 0.5285\n",
      "ROUGEScores - {'rouge1': np.float64(0.0), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.0), 'rougeLsum': np.float64(0.0)}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rouges_results_raw, bert_results_raw = evaluate_model(model_raw, dataset_test_1)\n",
    "\n",
    "results_raw = {\n",
    "    \"rouge\": rouges_results_raw,\n",
    "    \"bert\": bert_results_raw\n",
    "}\n",
    "\n",
    "with open(\"mt5_evaluation_results_raw.json\", \"w\") as f:\n",
    "    json.dump(results_raw, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
